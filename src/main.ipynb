{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "# import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "folder=\"./dataset\"\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "# transform = transforms.Compose([transforms.Resize((224, 224))])\n",
    "data_train_val=torchvision.datasets.FashionMNIST(root=folder,train=True,download=True,transform=None)\n",
    "data_test=torchvision.datasets.FashionMNIST(root=folder,train=False,download=True,transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=data_test.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# figure = plt.figure(figsize = (8,8))\n",
    "# cols, rows = 4, 4\n",
    "# ids=torch.randint(len(data_test), size = (cols*rows,))\n",
    "# for i in range (1, cols*rows + 1):\n",
    "#     image, label = data_test[ids[i-1].item()]\n",
    "#     figure.add_subplot(rows, cols, i)\n",
    "#     plt.title(classes[label])\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(image.squeeze(), cmap='gray')\n",
    "#     # plt.imshow(image.squeeze())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_train_val.data[:2000].shape\n",
    "data_test.data.shape\n",
    "# type(data_train_val.data)\n",
    "# data_test.targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation (10 points)\n",
    "- (a) Data cleansing and transformation (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, targets, trans=None):\n",
    "        self.x = inputs\n",
    "        self.y = targets\n",
    "        self.trans=trans\n",
    "        \n",
    "        # # for loss function\n",
    "        # self.pos_indices = np.flatnonzero(targets==1)\n",
    "        # self.pos_index_map = {}\n",
    "        # for i, idx in enumerate(self.pos_indices):\n",
    "        #     self.pos_index_map[idx] = i\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.size()[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # self.mode = 'train' #TODO\n",
    "        # if self.mode == 'train':\n",
    "        #    idx2 = self.pos_index_map[idx] if idx in self.pos_indices else -1\n",
    "\n",
    "        if self.trans == None:\n",
    "            # return (idx2, self.x[idx], self.y[idx])\n",
    "            # print(\"no trans\")\n",
    "            return ( self.x[idx], self.y[idx])\n",
    "        else:\n",
    "            # return (idx2, self.trans(self.x[idx]), self.y[idx]) \n",
    "            # print(\"trans\")\n",
    "            return ( self.trans(self.x[idx]), self.y[idx]) \n",
    "\n",
    "def ds_trans(ds_input,trans_flag):\n",
    "    data_input=ds_input.data.clone().detach()\n",
    "    labels_input=ds_input.targets\n",
    "    if data_input.ndim <= 3:\n",
    "        transform_train_val = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((64, 64)), \n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomAffine(degrees=(0,3), translate=(0,0.05), scale=None, shear=(0,0.05)),\n",
    "            transforms.RandomResizedCrop(size=(64,64),scale=(0.9,1.0),ratio=(0.9,1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0.5, 0.5)\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((64, 64)), \n",
    "            transforms.ToTensor(),\n",
    "             transforms.Normalize(0.5, 0.5)\n",
    "        ])\n",
    "        # transform_train_val = v2.Compose([\n",
    "        #     v2.ToPILImage(),\n",
    "        #     v2.Resize((64, 64)), \n",
    "        #     v2.RandomHorizontalFlip(0.5),\n",
    "        #     v2.RandomResizedCrop(size=(64,64),scale=(0.9,1.0),ratio=(0.9,1.1)),\n",
    "        #     v2.ToTensor(),\n",
    "        #     v2.Normalize(0.5, 0.5)\n",
    "        # ])\n",
    "        # transform_test = v2.Compose([\n",
    "        #     v2.ToPILImage(),\n",
    "        #     v2.Resize((64, 64)), \n",
    "        #     v2.ToTensor(),\n",
    "        #     v2.Normalize(0.5, 0.5)\n",
    "        # ])\n",
    "    elif data_input.ndim == 4:\n",
    "        # Should not come here\n",
    "        print(\"WRONG!\")\n",
    "\n",
    "    # data_input = data_input/255.0\n",
    "    if torch.isnan(data_input).any():\n",
    "        print(\"have NaN or Inf\")\n",
    "    # data_input = data_input.clone().detach()\n",
    "    # data_input = torch.tensor(data_input, dtype=torch.float32)\n",
    "    data_input = data_input[:,None,:,:]\n",
    "    print(data_input.shape)\n",
    "    # flag_labels = torch.tensor(flag_labels) \n",
    "    # flag_labels = flag_labels[:,None]\n",
    "    # print(flag_labels.shape)\n",
    "    \n",
    "    if trans_flag==1:\n",
    "        flag_ds_new = dataset(data_input, labels_input, trans=transform_train_val)\n",
    "    elif trans_flag==2:\n",
    "        flag_ds_new = dataset(data_input, labels_input, trans=transform_test)\n",
    "    else:\n",
    "        flag_ds_new = dataset(data_input, labels_input, trans=None)\n",
    "    return (flag_ds_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.16.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n",
      "torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "ds_processed_train_val=ds_trans(ds_input=data_train_val,trans_flag=1)\n",
    "ds_processed_test=ds_trans(ds_input=data_test,trans_flag=2)\n",
    "# ds_processed.x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (b) Data splitting (i.e., training, validation, and test splits) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# ds_processed_train_split, ds_processed_val_split = torch.utils.data.random_split(data_train_val, [50000, 10000]) \n",
    "# indices_train=ds_processed_train_split.indices\n",
    "# indices_val=ds_processed_val_split.indices\n",
    "\n",
    "random_seed=22\n",
    "indices = list(range(data_train_val.targets.shape[0]))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "indices_train=indices[:50000]\n",
    "indices_val=indices[50000:]\n",
    "\n",
    "ds_processed_train_sampler=SubsetRandomSampler(indices_train)\n",
    "ds_processed_val_sampler=SubsetRandomSampler(indices_val)\n",
    "\n",
    "# batch_size=64\n",
    "batch_size=256\n",
    "num_workers=10\n",
    "loader_train = torch.utils.data.DataLoader(ds_processed_train_val, batch_size=batch_size,sampler=ds_processed_train_sampler,\n",
    "                                            num_workers=num_workers)\n",
    "loader_val = torch.utils.data.DataLoader(ds_processed_train_val, batch_size=batch_size,sampler=ds_processed_val_sampler,\n",
    "                                            num_workers=num_workers)\n",
    "loader_test = torch.utils.data.DataLoader(ds_processed_test, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 64, 64])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(loader_train):\n",
    "    break\n",
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader_train)\n",
    "len(loader_train.sampler)\n",
    "# len(loader_train.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device ='cuda' if torch.cuda.is_available else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\n",
    "model=torchvision.models.vgg11()\n",
    "# model\n",
    "# model.conv1=torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.features[0]=torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "model=model.to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "\n",
    "# Loss Function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloop (dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X,y=X.to(device),y.to(device)\n",
    "        \n",
    "        # Compute the error rate\n",
    "        prediction = model(X)\n",
    "        loss = loss_fn(prediction, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f'loss:{loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "            \n",
    "def evaluate (dataloader, model, loss_fn):\n",
    "    # size = len(dataloader.dataset)\n",
    "    size = len(dataloader.sampler)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss:6.892178 [    0/60000]\n",
      "loss:0.762069 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 80.1%, Avg loss: 0.502812 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 80.2%, Avg loss: 0.507319 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 81.3%, Avg loss: 0.490604 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss:0.485747 [    0/60000]\n",
      "loss:0.411733 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 85.4%, Avg loss: 0.381774 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 84.7%, Avg loss: 0.388760 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 85.4%, Avg loss: 0.385210 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss:0.355748 [    0/60000]\n",
      "loss:0.329160 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 87.3%, Avg loss: 0.344790 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 87.0%, Avg loss: 0.365970 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 87.2%, Avg loss: 0.364851 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss:0.252668 [    0/60000]\n",
      "loss:0.299869 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 89.3%, Avg loss: 0.289533 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 88.5%, Avg loss: 0.311894 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 89.5%, Avg loss: 0.289731 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss:0.319065 [    0/60000]\n",
      "loss:0.278706 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 89.9%, Avg loss: 0.272513 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 89.0%, Avg loss: 0.298733 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 89.5%, Avg loss: 0.298184 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss:0.344812 [    0/60000]\n",
      "loss:0.236915 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 90.8%, Avg loss: 0.246141 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 90.1%, Avg loss: 0.276375 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 90.2%, Avg loss: 0.275257 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss:0.271041 [    0/60000]\n",
      "loss:0.226625 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 91.8%, Avg loss: 0.220269 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 90.9%, Avg loss: 0.251314 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 91.1%, Avg loss: 0.249377 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss:0.161119 [    0/60000]\n",
      "loss:0.255951 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 92.2%, Avg loss: 0.208596 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 91.3%, Avg loss: 0.240072 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 91.1%, Avg loss: 0.242556 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss:0.282936 [    0/60000]\n",
      "loss:0.234797 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 92.6%, Avg loss: 0.197571 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 91.3%, Avg loss: 0.244243 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 91.6%, Avg loss: 0.257673 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss:0.218165 [    0/60000]\n",
      "loss:0.148826 [25600/60000]\n",
      "Training Dataset Error:\n",
      "Accuracy: 92.5%, Avg loss: 0.202796 \n",
      "\n",
      "Validation Dataset Error:\n",
      "Accuracy: 91.4%, Avg loss: 0.240681 \n",
      "\n",
      "Test Dataset Error:\n",
      "Accuracy: 90.8%, Avg loss: 0.252971 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "    trainloop(loader_train, model, loss_fn, optimizer)\n",
    "    print(\"Training Dataset Error:\")\n",
    "    evaluate(loader_train, model, loss_fn)\n",
    "    print(\"Validation Dataset Error:\");\n",
    "    evaluate(loader_val, model, loss_fn)\n",
    "    print(\"Test Dataset Error:\");\n",
    "    evaluate(loader_test, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
